{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PCA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajArPatra/Dimentionality-Reduction/blob/main/PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g2TlknZAIDK"
      },
      "source": [
        "Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34YGe2ritJ0Q",
        "outputId": "97862b9b-5ac1-45e6-ca9e-19ed35b458fe"
      },
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=1Nl-RU5HggCSWWqINN4gbxHAVzER6T2Po&export=download\n",
        "!gzip -d /content/HIGGS_6M.csv.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1Nl-RU5HggCSWWqINN4gbxHAVzER6T2Po\n",
            "To: /content/HIGGS_6M.csv.gz\n",
            "1.56GB [00:08, 180MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr6gd8XwWVwN"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import os\n",
        "import numpy as np\n",
        "from skimage import io,transform as ts\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG8WAD98ATWW"
      },
      "source": [
        "Preparation train and test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcaLuyClKjFe"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "df= pd.read_csv('/content/HIGGS_6M.csv')\n",
        "\n",
        "df=df.replace([np.inf, -np.inf],np.nan)\n",
        "#print(df.isnull().sum())\n",
        "df1=df.iloc[:-500000]\n",
        "df2=df.iloc[-500000:]\n",
        "\n",
        "np.save('train.npy', df1.to_numpy(),True)\n",
        "np.save('test.npy', df2.to_numpy(),True)\n",
        "del df,df1,df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74swktl-QS-D"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC5RtLRNJS5W"
      },
      "source": [
        "# Dimentionality Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K-GIboEJalB"
      },
      "source": [
        "PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OawSh0jtJfLS"
      },
      "source": [
        "x1=np.load('train.npy',allow_pickle=True)\n",
        "x2= np.load('test.npy',allow_pickle=True)\n",
        "\n",
        "x=np.concatenate((x1,x2),0)\n",
        "del x1,x2\n",
        "standardizer =StandardScaler()\n",
        "x[:,1:] = standardizer.fit_transform(x[:,1:])\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "principalComponents = pca.fit_transform(x[:,1:])\n",
        "\n",
        "principalComponents=np.concatenate((x[:,0].reshape(-1,1),principalComponents),1)\n",
        "np.save('train_pca.npy',principalComponents[:-500000],True)\n",
        "np.save('test_pca.npy', principalComponents[-500000:],True)\n",
        "del x,principalComponents"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}